
# 数据清洗及可视化

---

### 实验内容

数据清洗是数据分析中非常重要的一部分，也最繁琐，做好这一步需要大量的经验和耐心。这门课程中，我将和大家一起，一步步完成这项工作。大家可以从这门课程中学习数据清洗的基本思路以及具体操作，同时，练习使用 Pandas 数据分析工具、Seaborn 统计分析可视化工具。

### 实验知识点

*   离群点分析
*   缺失值处理
*   偏态分布数据处理

---

### 实验步骤

### 环境准备

#### 下载数据


```python
!wget -nc http://labfile.oss.aliyuncs.com/courses/1001/train.csv #数据来源www.kaggle.com
```

**☞ 动手练习：**


```python

```

接下来，导入所需模块


```python
import pandas as pd
import numpy as np
import matplotlib as plt
import seaborn as sns
%matplotlib inline

data = pd.read_csv('train.csv') #读取数据，命名为 data
data.head(5) #查看 data 前5行
```


```python

```

示例结果：

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

##### 数据特征介绍


```python
data.columns #查看特征向量
```


```python

```

示例结果：
```
Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
      dtype='object')
```

我们导入的数据集 data，每行是一个训练样例（即游客），每列是该样例的特征。 其中 Suivived 代表游客是否存活（0 或 1），这是一个二分类问题（死亡 或 生存）。下面是各特征的详细说明：

*   PassengerId: 编号
*   Survived: 0 = 死亡，1 = 生存
*   Pclass: 船票级别 1 = 高级， 2 = 中等， 3 = 低等
*   Name: 名称
*   Sex: male = 男性，female = 女性
*   Age: 年龄
*   SibSp: 在 Titanic 上的兄弟姐妹以及配偶的人数
*   Parch: 在 Titanic 上的父母以及子女的人数
*   Ticket: 船票编号
*   Fare: 工资
*   Cabin: 所在的船舱
*   Embarked: 登船的港口 C = Cherbourg, Q = Queenstown, S = Southampton

##### 检查数据

检查数据的第一步是完整性。


```python
len(data) #数据集长度
```


```python

```

示例结果：

```
891
```


```python
data.isnull().sum()  #查看 null 值，查看非空使用 notnull()
```


```python

```

示例结果：

```
PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
```

总共有 891 个游客的数据，177 个 Age 缺失，687 个 Cabin 缺失，2 个 Embarked 缺失。在后面我们需要用不同的方法补充这些数据。

然后，我们查看特征类别分布是否平衡。类别平衡指分类样例不同类别的训练样例数目差别不大。当差别很大时，为类别不平衡。当类别不平衡的时候，例如正反比为 9:1，学习器将所有样本判别为正例的正确率都能达到 0.9。这时候，我们就需要使用 “再缩放”、“欠采样”、“过采样”、“阈值移动” 等方法。


```python
sns.countplot(x='Survived',data=data) #对不同值的 'Survived' 进行计数并绘图
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837824521.png)

图的纵坐标表示在不同类别下的人数。相差不是特别大，我们认为属于类别平衡问题。

接下来，我们查看特征值分布和格式。在这里，我们观察每个特征特征值是什么格式，怎么分布，维度如何。


```python
data.head(5)
```


```python

```

示例结果：

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

*   Cabin, Embarked 等特征值数值化
*   Ticket 等高维数据降维处理并将特征值数值化
*   Fare，Age 等为连续数据，之后需要检查是否是偏态数据

接下来，删除无用的特征 `PassengerId`, `Name`。


```python
data.drop(['PassengerId','Name'],axis=1,inplace=True) #删除 data['PassengerId','Name'] 两列数据，axis=1 表示删除列，axis=0 表示删除行，inplace=True 原位删除
data.columns
```


```python

```

示例结果：

```
Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',
       'Cabin', 'Embarked'],
      dtype='object')
```

#### 相关系数

参考 [知乎关于相关系数、协方差的讨论](https://www.zhihu.com/question/20852004/answer/129508585)


```python
g=sns.heatmap(data[['Survived','SibSp','Parch','Age','Fare','Pclass']].corr(),cmap='RdYlGn',annot=True) #corr() 计算相关系数，cmap 选择 color map，annot=True 显示相关系数
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837831381.png)

数值越大，相关性越大。Fare 和 Survived 有较大的正相关性。但这并不能说明其它的特征与 Survived 无关。

#### 缺失值

根据不同的情况，可以使用中位数、平均值、众数填充，删除等方法处理缺失数据，更复杂的还有建模预测。

##### Age

作图 Age ~ Survived。年龄较小的孩子生存的几率大。补充缺失值后，我们必须检查是否对 Age ~ Survived 的性质产生影响。


```python
Age0=data[(data['Survived']==0)&(data['Age'].notnull())]['Age'] #死亡乘客的 Age 数据
Age1=data[(data['Survived']==1)&(data['Age'].notnull())]['Age'] #生存乘客的 Age 数据
g=sns.kdeplot(Age0,legend=True,shade=True,color='r',label='NotSurvived') #死亡乘客年龄概率分布图， shade=True 设置阴影
g=sns.kdeplot(Age1,legend=True,shade=True,color='b',label='Survived') #生存乘客概率分布图
```


```python

```

示例结果： 

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837836142.png)

在 2.2.2 节中，根据 heatmap, Age 和 SibSp, Parch, Pclass 相关性高，我们再用箱型图直观感受下，以图形 Sex ~ Age, Pclass ~ Age 为例。


```python
g=sns.factorplot(x='Sex',y='Age',data=data,kind='box') 
g=sns.factorplot(x='Pclass',y='Age',data=data,kind='box')
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837840675.png) 

上面两图说明男性和女性的年龄分布（指箱型图中的五条线，从上到下依次是最大值、四分位数、中位数、四分位数、最小值）基本一致，而购买不同等级票的人的年龄分布是不同的。所以，我们根据票的等级将数据分为不同的集合，再用缺失数据所在集合的平均值来进行填充，并检查填充后 Age ~ Survived 是否受到影响。


```python
index = list(data[data['Age'].isnull()].index) #Age 缺失样例的 index
Age_mean = np.mean(data[data['Age'].notnull()]['Age']) #求平均值
copy_data = data.copy()
for i in index:
    filling_age = np.mean(copy_data[(copy_data['Pclass'] == copy_data.iloc[i]['Pclass'])
                                    & (copy_data['SibSp'] == copy_data.iloc[i]['SibSp'])
                                    & (copy_data['Parch'] == copy_data.iloc[i]['Parch'])
                                    ]['Age'])
    if not np.isnan(filling_age): # filling_age 非空为真
        data['Age'].iloc[i] = filling_age #填充 null 值
    else: # filling_age 空为真
        data['Age'].iloc[i] = Age_mean
g = sns.kdeplot(Age0, legend=True, shade=True, color='r', label='NotSurvived')
g = sns.kdeplot(Age1, legend=True, shade=True, color='b', label='Survived')
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837836142.png)

##### Embarked

对于只有极少数缺失值的特征，我们可以选择删除该样例，使用众数、均值、中位数填充。

##### Cabin

对于这种复杂，高维的数据，我们需要挖掘它的规律。例如 Cabin 特征值由字母开头，判断船舱按字母分为 A，B，C...

于是我们仅提取字母编号，降低维度。然后使用新的字母‘U’填充缺失数据。


```python
data[data['Cabin'].notnull()]['Cabin'].head(10)
```


```python

```

示例结果：

```
1             C85
3            C123
6             E46
10             G6
11           C103
21            D56
23             A6
27    C23 C25 C27
31            B78
52            D33
Name: Cabin, dtype: object
```


```python
# fillna() 填充 null 值
data['Cabin'].fillna('U',inplace=True) 

# 使用 lambda 表达式定义匿名函数对 i 执行 list(i)[0]。map() 指对指定序列 data ['Cabin'] 进行映射，对每个元素执行 lambda 
data['Cabin']=data['Cabin'].map(lambda i: list(i)[0]) 

# kind='bar' 绘制条形图，ci=False 不绘制概率曲线，order 设置横坐标次序
g = sns.factorplot(x='Cabin',y='Survived',data=data,ci=False,kind='bar',order=['A','B','C','D','E','F','T','U']) 
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837845448.png)


```python
g = sns.countplot(x='Cabin',hue='Pclass',data=data,order=['A','B','C','D','E','F','T','U']) # hue='Pclass' 表示根据 'Pclass' 进行分类
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837850212.png) 

从上面的图中看得出，缺失数据的游客主要是三等舱的，并且这部分游客的生存率相对较低。

#### 偏态分布

偏态分布的数据有时不利于模型发现数据中的规律，我们可以使用 Log Transformation 来处理数据，参考 [Skewed Distribution and Log Transformation](http://www.statisticshowto.com/probability-and-statistics/skewed-distribution/)

##### Fare


```python
g=sns.kdeplot(data[data['Survived']==0]['Fare'],shade='True',label='NotSurvived',color='r') # 死亡乘客 'Fare' 分布
g=sns.kdeplot(data[data['Survived']==1]['Fare'],shade='True',label='Survived',color='b') # 生存乘客 'Fare' 分布
```


```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837854241.png)

Fare 属于右偏态分布，Python 提供了计算数据偏态系数的函数 skew(), 计算值越大，数据偏态越明显。使用 Log Transformation 后，我们看到计算值从 4.79 降到 0.44。


```python
data['Fare']=data['Fare'].map(lambda i:np.log(i) if i>0 else 0) # 匿名函数为对非零数据进行 Log Transformation，否则保持零值
g=sns.distplot(data['Fare'])
print('Skew Coefficient:%.2f' %(data['Fare'].skew())) # skew() 计算偏态系数
```


```python

```

示例结果： 

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534837858432.png)

#### 数值化和标准化

##### Ticket

Ticket 特征值中的一串数字编号对我们没有意义，忽略。下面代码中，我们用正则表达式过滤掉这串数字，并使用 pandas get_dummies 函数进行数值化（以 Ticket 特征值 作为新的特征，0,1 作为新的特征值）。参考[正则表达式](https://www.cnblogs.com/huxi/archive/2010/07/04/1771072.html)


```python
Ticket=[]
import re
r=re.compile(r'\w*')#正则表达式，查找所有单词字符[a-z/A-Z/0-9]
for i in data['Ticket']:
    sp=i.split(' ')#拆分空格前后字符串，返回列表
    if len(sp)==1:
       Ticket.append('U')#对于只有一串数字的 Ticket，Ticket 增加字符 'U'
    else:
       t=r.findall(sp[0])#查找所有单词字符，忽略符号，返回列表
       Ticket.append(''.join(t))#将 t 中所有字符串合并
data['Ticket']=Ticket
data=pd.get_dummies(data,columns=['Ticket'],prefix='T')#get_dummies：如果DataFrame的某一列中含有k个不同的值，则可以派生出一个k列矩阵或DataFrame（其值全为1和0）
```


```python

```


```python
data.columns
```


```python

```

示例结果：

```
Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin',
       'Embarked', 'T_A4', 'T_A5', 'T_AS', 'T_C', 'T_CA', 'T_CASOTON', 'T_FC',
       'T_FCC', 'T_Fa', 'T_PC', 'T_PP', 'T_PPP', 'T_SC', 'T_SCA4', 'T_SCAH',
       'T_SCOW', 'T_SCPARIS', 'T_SCParis', 'T_SOC', 'T_SOP', 'T_SOPP',
       'T_SOTONO2', 'T_SOTONOQ', 'T_SP', 'T_STONO', 'T_STONO2', 'T_SWPP',
       'T_U', 'T_WC', 'T_WEP'],
      dtype='object')
```

##### Sex

Sex 只有 male, female 两个特征值，用 0 替代 male, 1 替代 female。


```python
data['Sex'].replace('male',0,inplace=True)#inplace=True 原位替换
data['Sex'].replace('female',1,inplace=True)
```


```python

```

#### 离群点

离群点是显著偏离数据集中其余对象的点。离群点来源于操作失误，数据本身的可变性等。在不同的环境中，离群点扮演不同角色。例如一个人的年龄 300 岁，应予以删除，而某些环境中，我们却需要探测、研究离群点，例如欺诈检测。

我们这里采用箱线法, 检测特征 ['Age', 'Parch', 'SibSp', 'Fare'] 的离群点。参考[离群点和箱线法](http://blog.csdn.net/littlely_ll/article/details/68486537)


```python
from collections import Counter

def outlier_detect(n, df, features):#定义函数 outlier_detect 探测离群点，输入变量 n, df, features，返回 outlier
    outlier_index = []
    for feature in features:
        Q1 = np.percentile(df[feature], 25)#计算上四分位数（1/4）
        Q3 = np.percentile(df[feature], 75)#计算下四分位数（3/4）
        IQR = Q3 - Q1
        outlier_span = 1.5 * IQR
        col = ((data[data[feature] > Q3 + outlier_span]) |
               (data[data[feature] < Q1 - outlier_span])).index
        outlier_index.extend(col)
        print('%s: %f (Q3+1.5*IQR) , %f (Q1-1.5*QIR) )' %
              (feature, Q3 + outlier_span, Q1 - outlier_span))
    outlier_index = Counter(outlier_index)#计数
    outlier = list(i for i, j in outlier_index.items() if j >= n)
    print('number of outliers: %d' % len(outlier))
    print(df[['Age', 'Parch', 'SibSp', 'Fare']].loc[outlier])
    return outlier

outlier = outlier_detect(3, data, ['Age', 'Parch', 'SibSp', 'Fare'])#调用函数 outlier_detect
```


```python

```

示例结果：

```
Age: 59.500000 (Q3+1.5*IQR) , -0.500000 (Q1-1.5*QIR) )
Parch: 0.000000 (Q3+1.5*IQR) , 0.000000 (Q1-1.5*QIR) )
SibSp: 2.500000 (Q3+1.5*IQR) , -1.500000 (Q1-1.5*QIR) )
Fare: 5.482703 (Q3+1.5*IQR) , 0.019461 (Q1-1.5*QIR) )
number of outliers: 4
      Age  Parch  SibSp      Fare
438  64.0      4      1  5.572154
27   19.0      2      3  5.572154
88   23.0      2      3  5.572154
341  24.0      2      3  5.572154
```

这里我们检测出 4 个离群点，使用 drop 函数删除即可。

### 实验总结

本实验我们介绍了数据清洗的基本思路，大家不仅需要掌握数据清洗的基础知识，还要善于利用数据分析工具。同时，不同环境，数据清洗的方法不同，这就要求我们多做练习。

## 课后作业

*   判断特征 Age 是否属于偏态分布
*   补全 Cabin 缺失值后，对该特征进行数值化处理
*   补全 Embarked 缺失值，对该特征进行数值化处理
*   思考 2.2.6 节中的得到的离群点是否应该删除

<div style="color: #999;font-size: 12px;">©️ 本课程内容，由作者授权实验楼发布，未经允许，禁止转载、下载及非法传播。</div>
