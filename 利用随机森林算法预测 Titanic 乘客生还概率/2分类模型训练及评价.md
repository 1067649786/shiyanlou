
# 分类模型训练及评价

---

### 实验内容

实验将评估不同模型的测试精度以及过拟合问题。学习器没有最好，只有适不适合，模型评估和性能度量的重要性可想而知。比起上节课，这节课将会轻松愉快很多。我们重点在模型评估的实现过程，对分类算法不了解的不用担心，实验 3 中，我们将对算法以及进行深入学习。

### 实验知识点

*   交叉验证法
*   过拟合
*   学习曲线

---

### 实验步骤

### 环境准备

#### 下载数据


```python
!wget http://labfile.oss.aliyuncs.com/courses/1001/data.csv  #经过完整数据清洗后的数据
```

    --2019-02-20 06:31:42--  http://labfile.oss.aliyuncs.com/courses/1001/data.csv
    Resolving labfile.oss.aliyuncs.com (labfile.oss.aliyuncs.com)... 47.110.177.159
    Connecting to labfile.oss.aliyuncs.com (labfile.oss.aliyuncs.com)|47.110.177.159|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 106591 (104K) [text/csv]
    Saving to: ‘data.csv’
    
    data.csv            100%[===================>] 104.09K  --.-KB/s    in 0s      
    
    2019-02-20 06:31:42 (277 MB/s) - ‘data.csv’ saved [106591/106591]
    


**☞ 动手练习：**


```python

```

### 模型评估

#### 模型选择

学习器在训练集上的误差称为 “训练误差” 或者 “经验误差”，在新的样本上的误差称为“泛化误差”。我们希望得到的是泛化误差小的学习器。通常，我们利用“测试集” 来测试学习器对新样本的判别能力，以得到的 “测试误差” 来近似泛化误差。基于这种思想的学习器的评估方法，有留出法、k 折交叉验证法、留一法、自助法：

*   留出法 (hold-out)：将数据集 D 划分为训练集 S 和测试集 T。通常 S 与 T 比例为 2/3 ~ 4/5。

*   k 折交叉验证（k-fold cross validation）：将 D 划分 k 个大小相似的子集（每份子集尽可能保持数据分布的一致性：子集中不同类别的样本数量比例与 D 基本一致），其中一份作为测试集，剩下 k-1 份为训练集 T，操作 k 次。 例如 D 划分为 D1，D2，... ，D10，第一次使用 D1 作为测试集，第二次使用 D2，第三次使用 D3， ... ， 第十次使用 D10 作为测试集。最后计算 k 次测试误差的平均值近似泛化误差。

*   留一法（Leave-One-out）：k 折交叉验证法的特例，即每次测试集 T 只留一个数据，剩下的作为训练集 S

*   自助法（bootstrapping）：每次从数据集 D 中有放回地采一个样本，并将这个样本放入训练集 S 中，重复 m 次。则训练集中有 m 个训练样本，将未在训练集中的样本放入测试集 T。

留出法和 k 折交叉验证法需要划分一部分样本作为测试集，就引入由于训练样本规模不同而产生的偏差。留一法改善了这一问题，但计算复杂度高。自助法也改善了这一个问题，但改变了数据集分布，同样会引入偏差，该方法适合数据集较小的情况。所以，留出法和 k 折交叉验证法是最常用的。这里选择 k 折交叉验证法进行模型评估。

Python sklearn.model_selection 提供了 Stratified k-fold。参考 [Stratified k-fold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)

我推荐使用 sklearn cross_val_score。这个函数输入我们选择的算法、数据集 D，k 的值，输出训练精度（误差是错误率，精度是正确率）。对于分类问题，默认采用 stratified k-fold 方法。参考 [sklearn cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)

下面我们用 10 折交叉验证法（k=10）对两种常用的集成学习算法 AdaBoost 以及 Random Forest 进行评估。最后我们看到 Random Forest 比 Adaboost 效果更好。


```python
import pandas as pd
import numpy as np
import matplotlib as plt
%matplotlib inline
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

data = pd.read_csv('data.csv')
data.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Survived</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Pc_1</th>
      <th>Pc_2</th>
      <th>Pc_3</th>
      <th>...</th>
      <th>T_SOPP</th>
      <th>T_SOTONO2</th>
      <th>T_SOTONOQ</th>
      <th>T_SP</th>
      <th>T_STONO</th>
      <th>T_STONO2</th>
      <th>T_SWPP</th>
      <th>T_WC</th>
      <th>T_WEP</th>
      <th>T_X</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>1.981001</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>4.266662</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>2.070022</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>3.972177</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>2.085672</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 52 columns</p>
</div>




```python

```

示例结果：

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Survived</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Pc_1</th>
      <th>Pc_2</th>
      <th>Pc_3</th>
      <th>...</th>
      <th>T_SOPP</th>
      <th>T_SOTONO2</th>
      <th>T_SOTONOQ</th>
      <th>T_SP</th>
      <th>T_STONO</th>
      <th>T_STONO2</th>
      <th>T_SWPP</th>
      <th>T_WC</th>
      <th>T_WEP</th>
      <th>T_X</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>1.981001</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>4.266662</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>2.070022</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>3.972177</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>2.085672</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>


```python
y = data['Survived']
X = data.drop(['Survived'], axis=1).values

classifiers = [AdaBoostClassifier(
    random_state=2), RandomForestClassifier(random_state=2)]
for clf in classifiers:
    score = cross_val_score(clf, X, y, cv=10, scoring='accuracy')#cv=10：10 折交叉验证法，scoring='accuracy'：返回测试精度
    print([np.mean(score)])#显示测试精度平均值
```

    [0.7353336738168198]
    [0.8047636477130858]



```python

```

示例结果：

```
[0.7353336738168198]
[0.8047636477130858]
```

#### 性能度量

过拟合是学习器性能过好，把样本的一些特性当做了数据的一般性质，从而导致训练误差低但泛化误差高。学习曲线是判断过拟合的一种方式，同时可以判断学习器的表现。学习曲线包括训练误差（或精度）随样例数目的变化曲线与测试误差（或精度）随样例数目的变化曲线。

下面我将以训练样例数目为横坐标，训练精度和测试精度为纵坐标绘制学习曲线，并分析 Random Forest 算法的性能。大家可以参考这篇博客进行深入学习 [学习曲线](https://www.cnblogs.com/llhthinker/p/5399827.html)


```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt

# 定义函数 plot_learning_curve 绘制学习曲线。train_sizes 初始化为 array([ 0.1  ,  0.325,  0.55 ,  0.775,  1\.   ]),cv 初始化为 10，以后调用函数时不再输入这两个变量

def plot_learning_curve(estimator, title, X, y, cv=10,
                        train_sizes=np.linspace(.1, 1.0, 5)):
    plt.figure()
    plt.title(title) # 设置图的 title
    plt.xlabel('Training examples') # 横坐标
    plt.ylabel('Score') # 纵坐标
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,
                                                            train_sizes=train_sizes) 
    train_scores_mean = np.mean(train_scores, axis=1) # 计算平均值
    train_scores_std = np.std(train_scores, axis=1) # 计算标准差
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid() # 设置背景的网格

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std,
                     alpha=0.1, color='g') # 设置颜色
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std,
                     alpha=0.1, color='r')
    plt.plot(train_sizes, train_scores_mean, 'o-', color='g',
             label='traning score') # 绘制训练精度曲线
    plt.plot(train_sizes, test_scores_mean, 'o-', color='r',
             label='testing score') # 绘制测试精度曲线
    plt.legend(loc='best')
    return plt

g = plot_learning_curve(RandomForestClassifier(), 'RFC', X, y) # 调用函数 plot_learning_curve 绘制随机森林学习器学习曲线
```


![png](output_32_0.png)



```python

```

示例结果：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid245411labid7970timestamp1534838690278.png)

Random Forest 的学习曲线我们得到了，训练误差始终接近 0，而测试误差始终偏高，说明存在过拟合的问题。这个问题的产生是因为 Random Forest 算法使用决策树作为基学习器，而决策树的一些特性将造成较严重的过拟合。这个问题的具体原因以及解决方法将在下一节课讲解。

### 实验总结

本实验我们使用交叉验证法以及学习曲线对模型选择和性能评估进行了实例讲解，并练习使用 sklearn 机器学习工具。下节课我们将深入学习如何真的随机森林分类器调参。

<div style="color: #999;font-size: 12px;">©️ 本课程内容，由作者授权实验楼发布，未经允许，禁止转载、下载及非法传播。</div>
